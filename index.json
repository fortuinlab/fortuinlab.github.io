[{"authors":null,"categories":null,"content":"I am a postdoc working at Helmholtz Institute in Munich supervised by Vincent Fortuin. I am generally interested in probabilistic approaches to Machine Learning and am currently especially interested in how to improve approximate Bayesian inference and how to learn priors for complex models.\nPrior to joining I completed my PhD at Imperial College London, supervised by Dr. Sarah Filippi and Prof. Ruth Misener. I worked on how to combine physics informed models with approximate Bayesian inference for use in pharmaceutical manufacturing.\n","date":1735689600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1735689600,"objectID":"03a05a0ca667c0a815d82e6808988a28","permalink":"https://fortuinlab.github.io/author/james-odgers/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/james-odgers/","section":"authors","summary":"I am a postdoc working at Helmholtz Institute in Munich supervised by Vincent Fortuin. I am generally interested in probabilistic approaches to Machine Learning and am currently especially interested in how to improve approximate Bayesian inference and how to learn priors for complex models.","tags":null,"title":"James Odgers","type":"authors"},{"authors":null,"categories":null,"content":"I embarked on my PhD journey in November 2023 at the Helmholtz AI and the Technical University of Munich, where I am supervised by Dr. Vincent Fortuin. Before this, I completed my research Master’s in Artificial Intelligence at the University of Amsterdam as an ELLIS MSc Honours student.\nMy primary research goal is to develop intelligent, safe, and robust agents that are capable of (1) not only learning efficiently but also understanding what they do not know, and (2) adapting to changes in data distributions. My main interests encompass probabilistic modeling, deep learning, approximate inference, deep generative models, and information theory. I am also excited about ideas related to imbuing neural networks with inductive biases (e.g., invariance and equivariance) and causality.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"489f333a7244a249e1c45c27e4113be8","permalink":"https://fortuinlab.github.io/author/arsen-sheverdin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/arsen-sheverdin/","section":"authors","summary":"I embarked on my PhD journey in November 2023 at the Helmholtz AI and the Technical University of Munich, where I am supervised by Dr. Vincent Fortuin. Before this, I completed my research Master’s in Artificial Intelligence at the University of Amsterdam as an ELLIS MSc Honours student.","tags":null,"title":"Arsen Sheverdin","type":"authors"},{"authors":null,"categories":null,"content":"I started my PhD in 2023 under the supervision of Vincent Fortuin and was working on better uncertainty-awareness for LLMs.\nI did my BSc in Physics at LMU, specializing in statistical physics.\nI have an MA degree in Logic and Philosophy of Science from the LMU, where I focused on Bayesian Epistemology, as well as an MSc degree in Computational Linguistics with a minor in Informatics from the LMU, where I focused on LLM benchmarking using hierarchical Bayesian models. I also spent some time as a working student at the Volkswagen Data Lab for AI Innovation working on classification of customer complaints and building an automotive training corpus.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"5f7733b3339a287d0ffaf4f9d3e5076a","permalink":"https://fortuinlab.github.io/author/emma-caldwell/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/emma-caldwell/","section":"authors","summary":"I started my PhD in 2023 under the supervision of Vincent Fortuin and was working on better uncertainty-awareness for LLMs.\nI did my BSc in Physics at LMU, specializing in statistical physics.","tags":null,"title":"Emma Caldwell","type":"authors"},{"authors":null,"categories":null,"content":"I am from Istanbul, Turkey and Geneva, Switzerland. I graduated summa cum laude from Princeton University in 2023, majoring in Operations Research \u0026amp; Financial Engineering with minors in Computer Science and Statistics \u0026amp; Machine Learning. Currently, I am pursuing my Master’s in Computer Science at Columbia University, which I will complete in December 2024.\nI am most interested in automating complex large-scale decision-making processes using statistics and machine learning. I have a diverse range of experiences in different areas of machine learning, from computer vision to natural language processing. My past research experiences have ranged from improving our understanding of feature learning in deep classification networks to optimizing ads ranking performance for Facebook ads using graph learning models. My most recent research project explored a simple and inexpensive way to integrate Bayesian neural networks with large language models by using Gaussian stochastic weight averaging in low-rank adaptation layers, resulting in improvements in model calibration and generalization performance across several natural language processing benchmarks.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"d25dfcc17772eafd559fb4625f3f6ba8","permalink":"https://fortuinlab.github.io/author/emre-onal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/emre-onal/","section":"authors","summary":"I am from Istanbul, Turkey and Geneva, Switzerland. I graduated summa cum laude from Princeton University in 2023, majoring in Operations Research \u0026 Financial Engineering with minors in Computer Science and Statistics \u0026 Machine Learning.","tags":null,"title":"Emre Onal","type":"authors"},{"authors":null,"categories":null,"content":"I started my PhD in 2023 co-supervised by Gunnar Rätsch and Vincent Fortuin. I work on informed, Bayesian, and representation machine learning with applications to medical data.\nI did my BSc in Applied Mathematics and Physics at MIPT, specializing in computational methods for physics simulations. In parallel, I developed deep learning models for high-energy physics at GSI and LAMBDA.\nIn my MSc I studied Computational Sciences and Engineering at EPFL, combining my interest in numerical and data-driven modeling. I interned at startup companies Spiden and Neural Concept, where I worked on synthetic data generation for medical devices and 3D computer vision for engineering. My master’s thesis focused on physics-informed neural networks for fluid flow modeling.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"e056289e32160f1af64f3f98d250186a","permalink":"https://fortuinlab.github.io/author/fedor-sergeev/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/fedor-sergeev/","section":"authors","summary":"I started my PhD in 2023 co-supervised by Gunnar Rätsch and Vincent Fortuin. I work on informed, Bayesian, and representation machine learning with applications to medical data.\nI did my BSc in Applied Mathematics and Physics at MIPT, specializing in computational methods for physics simulations.","tags":null,"title":"Fedor Sergeev","type":"authors"},{"authors":null,"categories":null,"content":"I am an MSc Computer Science graduate from ETH Zürich. I majored in Machine Intelligence and minored in Systems Software. My interests are data-driven scientific discovery through the design of specialized machine learning models, advancements in uncertainty quantification, and more broadly fundamental theory of deep learning.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"9745af6b2a0b8287dffe7062df021bdd","permalink":"https://fortuinlab.github.io/author/kouroche-bouchiat/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/kouroche-bouchiat/","section":"authors","summary":"I am an MSc Computer Science graduate from ETH Zürich. I majored in Machine Intelligence and minored in Systems Software. My interests are data-driven scientific discovery through the design of specialized machine learning models, advancements in uncertainty quantification, and more broadly fundamental theory of deep learning.","tags":null,"title":"Kouroche Bouchiat","type":"authors"},{"authors":null,"categories":null,"content":"I am an ELLIS PhD student at the University of Edinburgh, supervised by Antonio Vergari, Nikolay Malkin, and Vincent Fortuin. Through my research, I aim to develop reliable and efficient machine learning systems which comply with task-relevant constraints, such as safety rules or domain knowledge. I am broadly interested in anything related to neuro-symbolic learning and tractable uncertainty quantification.\nPreviously, I worked on knowledge graph reasoning and learning with noisy labels at the University of Vienna, where I also completed my Bachelor’s degree in Statistics and Master’s degree in Data Science.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"782cf8a6d2e6165a19b1e551951c315a","permalink":"https://fortuinlab.github.io/author/lena-zellinger/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/lena-zellinger/","section":"authors","summary":"I am an ELLIS PhD student at the University of Edinburgh, supervised by Antonio Vergari, Nikolay Malkin, and Vincent Fortuin. Through my research, I aim to develop reliable and efficient machine learning systems which comply with task-relevant constraints, such as safety rules or domain knowledge.","tags":null,"title":"Lena Zellinger","type":"authors"},{"authors":null,"categories":null,"content":"Maksym Tretiakov is currently pursuing his Master’s Thesis in Bayesian Machine Learning, under the supervision of Dr. Vincent Fortuin and Alexander Immer. Simultaneously, he is involved in a research project at Harvard University, guided by Ph.D. Leon Peshkin since October 2022, where he is exploring advanced techniques in Function-on-Function regression and neural network-based classification. Maksym’s prior research at the Institute of Mathematics of the National Academy of Sciences of Ukraine (Dec 2020 - May 2021) delved into the use of Hidden Markov Models for music chord recognition. His academic interests are diverse, encompassing Bayesian Machine Learning, Statistics, Finance, and Computational Biology.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"12f4cb026d2998fdd864cbee9cb1632a","permalink":"https://fortuinlab.github.io/author/maksym-tretiakov/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/maksym-tretiakov/","section":"authors","summary":"Maksym Tretiakov is currently pursuing his Master’s Thesis in Bayesian Machine Learning, under the supervision of Dr. Vincent Fortuin and Alexander Immer. Simultaneously, he is involved in a research project at Harvard University, guided by Ph.","tags":null,"title":"Maksym Tretiakov","type":"authors"},{"authors":null,"categories":null,"content":"Rayen Dhahri holds a Master’s degree in Robotics, Cognition, Intelligence from TU Munich. His thesis, supervised by Dr. Vincent Fortuin, Alexander Immer and Bertrand Charpentier, focused on developing methods to enhance the efficiency and compression of neural networks. Currently, Rayen is expanding his thesis work to encompass larger neural networks and modern architectures, aiming to demonstrate the generalization of their proposed method on newer architectures. He worked at BMW, deploying neural network models on microcontrollers, optimizing architectures for real-time applications, and generating custom kernels for ECUs. At Huawei, he developed a reinforcement learning fleet management framework, optimizing task assignments for robots based on available resources and task requirements, while enabling dynamic learning of new tasks. His research projects include proposing a teacher-student architecture for saliency prediction combined with data augmentation techniques at EPFL, developing neural network sparsification methods at Intel, combining hardware filters and machine learning for anomaly detection at Infineon Technologies, and generating kernels using LLVM for deploying models on RISC-V, contributing to the creation of an ELF Loader and optimizing memory layout for an Instruction Set Simulator.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"58fbb105ad7abc2729517a24e612085d","permalink":"https://fortuinlab.github.io/author/rayen-dhahri/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/rayen-dhahri/","section":"authors","summary":"Rayen Dhahri holds a Master’s degree in Robotics, Cognition, Intelligence from TU Munich. His thesis, supervised by Dr. Vincent Fortuin, Alexander Immer and Bertrand Charpentier, focused on developing methods to enhance the efficiency and compression of neural networks.","tags":null,"title":"Rayen Dhahri","type":"authors"},{"authors":null,"categories":null,"content":"PhD Student Bio I am a doctoral researcher at Helmholtz AI and the Technical University of Munich as a member of the Elpis lab, supervised by Dr. Vincent Fortuin. I am mentored by Mark van der Wilk. I am broadly motivated by the need to develop machine intelligence systems that can reason in the presence of uncertainty, as this strikes me as the most crippling flaw of current automated learning systems.\nPrior to my PhD, I took a year out of education to focus on expanding my knowledge of probabilistic machine learning. In addition to this, I wrote a single-author research paper that was accepted at AABI 2024, and spent five months as a Machine Learning Researcher at Motorway in London where I worked with scalable Bayesian machine learning models for various use cases in vehicle pricing.\nBefore my year out, I studied engineering at the University of Cambridge where my specialism was computer and information engineering, though my module choice made the integrated masters year indistinguishable from a typical masters in Machine Learning, albeit with a heavy dose of Bayesianism.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"eed449d6845cc4fbe27b8aaf6fac5cb1","permalink":"https://fortuinlab.github.io/author/tommy-rochussen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/tommy-rochussen/","section":"authors","summary":"PhD Student Bio I am a doctoral researcher at Helmholtz AI and the Technical University of Munich as a member of the Elpis lab, supervised by Dr. Vincent Fortuin. I am mentored by Mark van der Wilk.","tags":null,"title":"Tommy Rochussen","type":"authors"},{"authors":null,"categories":null,"content":"PhD Student Bio I am a PhD candidate in probabilistic machine learning at the University of Tübingen, co-supervised by Robert Bamler and Vincent Fortuin. My research focuses on Bayesian Neural Networks (BNNs), where I develop approximate Bayesian inference methods for uncertainty quantification in deep learning. Specifically, I work on techniques to specify informative function-space priors and scale Bayesian inference to larger datasets and more complex models.\nMy interests extend to model selection in neural networks and the application of BNNs to decision-making and optimization under uncertainty, including Bayesian optimization, multi-armed bandits, and active learning. I’m also exploring the integration of Bayesian principles into large language models to enhance text generation, calibration, and uncertainty quantification.\nI hold a Bachelor’s degree in Communication Systems from EPFL and a Master’s degree in Computer Science from ETH Zürich. During an internship as an Applied Scientist at Amazon in Berlin, I developed Bayesian inference methods for gradient boosting machines, focusing on well-calibrated predictive uncertainty for tabular data with applications to contextual bandit problems.\nThrough my research, I aim to contribute to the development of robust and reliable deep learning systems, particularly in applications where accurate uncertainty quantification is crucial for decision-making and risk assessment. My goal is to bridge the gap between theoretical advancements in Bayesian deep learning and their practical implementation in real-world scenarios.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"058a914fa35ceac745f1a5300a43d81f","permalink":"https://fortuinlab.github.io/author/tristan-cinquin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/tristan-cinquin/","section":"authors","summary":"PhD Student Bio I am a PhD candidate in probabilistic machine learning at the University of Tübingen, co-supervised by Robert Bamler and Vincent Fortuin. My research focuses on Bayesian Neural Networks (BNNs), where I develop approximate Bayesian inference methods for uncertainty quantification in deep learning.","tags":null,"title":"Tristan Cinquin","type":"authors"},{"authors":null,"categories":null,"content":"Vincent Fortuin is a tenure-track research group leader at Helmholtz AI in Munich, leading the group for Efficient Learning and Probabilistic Inference for Science (ELPIS), and a faculty member at the Technical University of Munich. He is also a Branco Weiss Fellow, an ELLIS Scholar, a Fellow of the Konrad Zuse School of Excellence in Reliable AI, and a Senior Researcher at the Munich Center for Machine Learning. His research focuses on reliable and data-efficient AI approaches leveraging Bayesian deep learning, deep generative modeling, meta-learning, and PAC-Bayesian theory. Before that, he did his PhD in Machine Learning at ETH Zürich and was a Research Fellow at the University of Cambridge. He is a regular reviewer and area chair for all major machine learning conferences, an action editor for TMLR, and a co-organizer of the Symposium on Advances in Approximate Bayesian Inference (AABI) and the ICBINB initiative.\n","date":1704067200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1704067200,"objectID":"9ef99e44a5b1b47523ad4aad6c4c8dc1","permalink":"https://fortuinlab.github.io/author/vincent-fortuin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/vincent-fortuin/","section":"authors","summary":"Vincent Fortuin is a tenure-track research group leader at Helmholtz AI in Munich, leading the group for Efficient Learning and Probabilistic Inference for Science (ELPIS), and a faculty member at the Technical University of Munich.","tags":null,"title":"Vincent Fortuin","type":"authors"},{"authors":null,"categories":null,"content":"Yauheni Mardan writes his Master’s thesis at Fortuinlab. Currently, he is a final-year Data Engineering and Analytics Master’s student at TU Munich, CIT. Additionally, he works part-time as a Junior Data Scientist at Check24 in the Learning to Rank team. Yauheni’s research interests are PAC-Bayes bounds and Bayesian Machine Learning.\n","date":1640995200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1640995200,"objectID":"15e584e9f559f7982a8480180c732630","permalink":"https://fortuinlab.github.io/author/yauheni-mardan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yauheni-mardan/","section":"authors","summary":"Yauheni Mardan writes his Master’s thesis at Fortuinlab. Currently, he is a final-year Data Engineering and Analytics Master’s student at TU Munich, CIT. Additionally, he works part-time as a Junior Data Scientist at Check24 in the Learning to Rank team.","tags":null,"title":"Yauheni Mardan","type":"authors"},{"authors":null,"categories":null,"content":"I’m Ajay Narayanan, a master’s student of Robotics, Cognition, Intelligence at TUM. I’m interested broadly in Machine Learning and AI, and specifically in Natural Language Processing and Graph Neural Networks. For my Master’s Seminar, I researched GNN-based methods in NLP, specifically related to the problem of multi-hop reading comprehension. As part of the research, we did an extensive literature survey on various GNN and non-GNN-based methods for the problem. For my Practicals, I worked on Graph-based Problem solving with LLMs and benchmarked those methods against well-known datasets. Ultimately, we created a runnable repository for future researchers to extend and use. In addition, I have over 6 years of professional experience in software development and working with agile teams.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"57bdfb8b378a095fce5226c9941b1e09","permalink":"https://fortuinlab.github.io/author/ajay-narayanan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ajay-narayanan/","section":"authors","summary":"I’m Ajay Narayanan, a master’s student of Robotics, Cognition, Intelligence at TUM. I’m interested broadly in Machine Learning and AI, and specifically in Natural Language Processing and Graph Neural Networks. For my Master’s Seminar, I researched GNN-based methods in NLP, specifically related to the problem of multi-hop reading comprehension.","tags":null,"title":"Ajay Narayanan","type":"authors"},{"authors":null,"categories":null,"content":"I am a PhD student at the University of Cambridge, co-supervised by Miguel Martins (University of Cambridge) and Manolis Kellis (MIT-CSAIL). I am also affiliated with the Sanger Institute, where I work with Mo Loftollahi. I previously worked as a computational biologist at the MIT with Prof. Kellis. I also conducted research under Nick Goldman at EMBL-EBI and with Ruben Van Boxtel at the Prinses Máxima Centrum voor Knderoncologie.\nMy research focuses on the development of innovative statistical and probabilistic machine learning models tailored for single-cell data analysis and data integration. By harnessing the power of these cutting-edge techniques, I aim to shed light on the underlying mechanisms of disease and pave the way for more targeted and effective therapeutic strategies. I have a strong interest in the heterogeneity of data, including demographic variations, and am fascinated by multi-modalities and multi-omics data. This approach is integral to my work, contributing to the broader understanding of neurodegenerative diseases through comprehensive and diverse data analysis. In collaboration with Vincent, his lab, and other collaborators at the Helmholtz Institute, I am dedicated to developing more robust models for data analysis. We aim to integrate epistemic and aleatoric uncertainty estimates in our models to provide insights on the reliability of the learned representations of single-cell data. Moreover, we delve into the realm of causal representation learning, in order to unravel the intricate connections between biological and environmental factors in the genesis of complex diseases.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9ada1b476f9c7d66d687b95c4dcabbd7","permalink":"https://fortuinlab.github.io/author/andrea-rubbi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/andrea-rubbi/","section":"authors","summary":"I am a PhD student at the University of Cambridge, co-supervised by Miguel Martins (University of Cambridge) and Manolis Kellis (MIT-CSAIL). I am also affiliated with the Sanger Institute, where I work with Mo Loftollahi.","tags":null,"title":"Andrea Rubbi","type":"authors"},{"authors":null,"categories":null,"content":"PhD Student Bio In July 2025, I will start as a relAI PhD student at Helmholtz Munich and the Technical University of Munich (TUM) as a member of the ELPIS lab, supervised by Dr. Vincent Fortuin. I aim to contribute to the reliable application of AI in science through better uncertainty quantification and robustness.\nI am currently working as a research associate at the Professorship of Energy Management Technologies at TUM, conducting applied ML research. My work focuses on reliable wind power forecasting and developing software for more efficient and streamlined ML development in the energy research community. Before that, I studied mathematics at TUM, focusing on probability theory, statistics, and financial applications.\nI strongly believe that Bayesian deep learning is a key approach for reliable AI for science. My PhD project aims to investigate how Bayesian principles can be applied safely in modern ML, how priors can be informed with previous knowledge, and how this leads to more reliable and data-efficient ML for scientific tasks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"be6be1b6793e877ef4d9c28ec019f7ad","permalink":"https://fortuinlab.github.io/author/annika-schneider/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/annika-schneider/","section":"authors","summary":"PhD Student Bio In July 2025, I will start as a relAI PhD student at Helmholtz Munich and the Technical University of Munich (TUM) as a member of the ELPIS lab, supervised by Dr.","tags":null,"title":"Annika Schneider","type":"authors"},{"authors":null,"categories":null,"content":"PhD Student Bio I am an ELLIS PhD student at the Helmholtz AI Institute in Munich, where I am supervised by Dr. Vincent Fortuin. As part of the ELLIS program, I am also supervised by Dr. Mark van der Wilk, at the University of Oxford. Next to a BSc in Econometrics from the University of Amsterdam, I hold an MSc in Statistical Sciences from the University of Oxford.\nMy PhD project aims to develop adaptive modeling techniques leveraging Meta-Learning algorithms to accelerate scientific research. In order to make Machine Learning methods useful for scientific discovery, they should be tailored to the problem setting of scientific research. This usually includes an underlying physical system, scarce and expensive data, availability of domain knowledge and the need for uncertainty quantification.\nI am interested in Meta-Learning, as it enables learning at a higher level, extracting patterns from related tasks to improve performance on new, unseen tasks. This allows such models to learn key properties of an underlying physical system, making Meta-Learning attractive in scientific settings.\nBy incorporating techniques from Bayesian Deep Learning, we can infuse uncertainty estimation and online learning capabilities into Meta-Learning frameworks. Uncertainty quantification is vital where mistakes are costly and can aid scientists in their decision-making process. This interaction of scientists with Machine-Learning models is highly desirable and should be facilitated by model design.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"70c266dd5cb5442504b5d3614d04a606","permalink":"https://fortuinlab.github.io/author/ben-riegler/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ben-riegler/","section":"authors","summary":"PhD Student Bio I am an ELLIS PhD student at the Helmholtz AI Institute in Munich, where I am supervised by Dr. Vincent Fortuin. As part of the ELLIS program, I am also supervised by Dr.","tags":null,"title":"Ben Riegler","type":"authors"},{"authors":null,"categories":null,"content":"PhD Student Bio I am a PhD candidate in Bayesian Machine Learning at the Helmholtz Institute in Munich where I am supervised by Dr. Vincent Fortuin. As part of the ELLIS program, I am also supervised by Prof. Jose Miguel Hernandez-Lobato at the University of Cambridge.\nMy broad interest lies in achieving human-like intelligence, especially in regards to dealing with uncertainty and adaptability to new circumstances. I believe Bayesian methods present a principled approach to these questions as well as exciting avenues for research. Specifically, I think about fast and scalable approximate inference algorithms, continual learning approaches, meta learning and other related topics. Alongside Bayesian ML, I am deeply interested in geometric machine learning, reinforcement learning, optimization, and generative AI.\nI hold a Master’s degree in Mathematics and Computer science from the University of Oxford. Before starting my PhD, I worked for several years as a software/quant developer. In this role I built fleet management systems for AVs as well as trading software for a cryptocurrency options desk. Most recently, I worked as a quant researcher at a small hedge fund. There, I researched machine learning methods for trading signals generation while also working on the MLOps pipeline for recomputing the signals when new data became available. Besides the roles at established companies, I was also an early developer/founder at several startups.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"276f13480782e01659a52ce94acc2d1c","permalink":"https://fortuinlab.github.io/author/blagovest-gospodinov/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/blagovest-gospodinov/","section":"authors","summary":"PhD Student Bio I am a PhD candidate in Bayesian Machine Learning at the Helmholtz Institute in Munich where I am supervised by Dr. Vincent Fortuin. As part of the ELLIS program, I am also supervised by Prof.","tags":null,"title":"Blagovest Gospodinov","type":"authors"},{"authors":null,"categories":null,"content":"Chia-Chian Chan is currently pursuing her Master’s thesis in Bayesian Physics-Informed Neural Networks, under the supervision of Dr. Vincent Fortuin and Fedor Sergeev. Currently, she is a final-years Computational Science and Engineering Master’s student at TU Munich, CIT. Chia-Chian’s research interests are Informed Machine Learning and Bayesian Deep Learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3c194985042c0f5deb31a1aa888cae42","permalink":"https://fortuinlab.github.io/author/chia-chian-chan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chia-chian-chan/","section":"authors","summary":"Chia-Chian Chan is currently pursuing her Master’s thesis in Bayesian Physics-Informed Neural Networks, under the supervision of Dr. Vincent Fortuin and Fedor Sergeev. Currently, she is a final-years Computational Science and Engineering Master’s student at TU Munich, CIT.","tags":null,"title":"Chia-Chian Chan","type":"authors"},{"authors":null,"categories":null,"content":"I am a graduate student at the Technical University of Munich, majoring in Mathematics with a minor in Informatics. I have two years of experience as a Junior Data Scientist in the Finance Development Department at Infineon Technologies, along with previous roles in machine learning and innovation labs. My interests lie in data-driven scientific discovery through the development of specialized machine learning models, as well as in deep learning, probabilistic modeling, and causal inference.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"eb6ba78961f1228300225c420f8a8708","permalink":"https://fortuinlab.github.io/author/denida-blloshmi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/denida-blloshmi/","section":"authors","summary":"I am a graduate student at the Technical University of Munich, majoring in Mathematics with a minor in Informatics. I have two years of experience as a Junior Data Scientist in the Finance Development Department at Infineon Technologies, along with previous roles in machine learning and innovation labs.","tags":null,"title":"Denida Blloshmi","type":"authors"},{"authors":null,"categories":null,"content":"I am an undergraduate student at Princeton University, majoring in mathematics with a minor in computer science. I am strongly interested in the intersection between mathematics and theoretical computer science, especially concerning probabilistic machine-learning algorithms. Prior to my undergraduate studies, I worked as a research assistant at Axle Informatics under Dr. Nicholas Schaub.\nMy research in Vincent’s lab focuses on the advancement of Bayesian Deep Learning models to supplement traditional applications of neural networks. I aim to improve the applicability of Bayesian machine learning by exploring the intricacies of how approximate inference methods in a Bayesian probabilistic framework interact with state-of-the-art learning models.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3ea8a8098cf2e96b8785b3521254aaaf","permalink":"https://fortuinlab.github.io/author/joshua-cheng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/joshua-cheng/","section":"authors","summary":"I am an undergraduate student at Princeton University, majoring in mathematics with a minor in computer science. I am strongly interested in the intersection between mathematics and theoretical computer science, especially concerning probabilistic machine-learning algorithms.","tags":null,"title":"Joshua Cheng","type":"authors"},{"authors":null,"categories":null,"content":"Keyan Shi is currently working on her Master’s thesis titled “Hybrid Physics-ML Modeling with Zero-Order Optimization”, under the joint supervision of Dr. Vincent Fortuin and Dr. Gideon Dresdner.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f3f742d822ca34bb78a46cab97e8052f","permalink":"https://fortuinlab.github.io/author/keyan-shi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/keyan-shi/","section":"authors","summary":"Keyan Shi is currently working on her Master’s thesis titled “Hybrid Physics-ML Modeling with Zero-Order Optimization”, under the joint supervision of Dr. Vincent Fortuin and Dr. Gideon Dresdner.","tags":null,"title":"Keyan Shi","type":"authors"},{"authors":null,"categories":null,"content":"I am a German national from Hannover and a PhD student in the ELPIS group, with a solid background in engineering and applied mathematics. My academic journey and professional experiences have equipped me with a deep understanding of technical principles and a passion for innovative solutions. I am particularly interested in applying Bayesian principles, especially uncertainty quantification, to large-scale AI systems, with a focus on transformer architectures and diffusion models.\nMy research interests are rooted in the potential of AI to transform industries and improve lives. I am deeply fascinated by the healthcare sector and protein analysis space, where I believe AI can make significant breakthroughs in understanding complex biological processes and developing new treatments. Additionally, my work explores the intricacies of natural language processing (NLP) and the challenges of quantifying uncertainties in large language models (LLMs). These areas are crucial for enhancing the reliability and interpretability of AI systems in real-world applications.\nMost of my applications are in the deep generative AI space, where I aim to push the boundaries of what is possible with current technologies. By leveraging my expertise in Bayesian methods and my keen interest in transformer architectures and diffusion models, I strive to contribute to the development of AI models that are not only powerful but also trustworthy and transparent. Through my research, I hope to address some of the most pressing challenges in AI, particularly in healthcare and NLP, and to pave the way for new discoveries that can benefit society at large.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"528e9dd771f6b6057e08c8ab105dd209","permalink":"https://fortuinlab.github.io/author/klemens-floge/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/klemens-floge/","section":"authors","summary":"I am a German national from Hannover and a PhD student in the ELPIS group, with a solid background in engineering and applied mathematics. My academic journey and professional experiences have equipped me with a deep understanding of technical principles and a passion for innovative solutions.","tags":null,"title":"Klemens Flöge","type":"authors"},{"authors":null,"categories":null,"content":"I am a PhD student at Helmholtz Munich Institute of AI for Health and at Technical University of Munich, under the supervision of Ewa Szczurek and Vincent Fortuin. My research focuses on generative modeling and properties optimization of antimicrobial peptides (AMPs).\nI completed my BEng in Biomedical Engineering and MEng in Data Science at AGH University of Science and Technology in Cracow. Prior to joining Helmholtz I worked at a contract research organization Selvita, where I contributed to various phases of the drug discovery pipeline, focusing on problems such as quantitative structure–activity relationship modeling (QSAR), lead optimization and modeling of compound-protein interactions.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"22afa2c550a7ded119f6db8cd1da4656","permalink":"https://fortuinlab.github.io/author/michal-kmicikiewicz/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/michal-kmicikiewicz/","section":"authors","summary":"I am a PhD student at Helmholtz Munich Institute of AI for Health and at Technical University of Munich, under the supervision of Ewa Szczurek and Vincent Fortuin. My research focuses on generative modeling and properties optimization of antimicrobial peptides (AMPs).","tags":null,"title":"Michal Kmicikiewicz","type":"authors"},{"authors":null,"categories":null,"content":"I’m a second-year PhD student from FZ Jülich and member of HDS-LEE, currently visiting the ELPIS group as a HIDA Trainee to learn and work on Bayesian deep learning for uncertainty-aware single-cell microscopy analysis.\nMy research interests cover many numerical and algorithmic problems arising from real-world problems, covering Bayesian statistics, probabilistic modeling, graph theory, and scientific deep learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"cda38e5afe13c3be47c2a53ac253517c","permalink":"https://fortuinlab.github.io/author/richard-d.-paul/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/richard-d.-paul/","section":"authors","summary":"I’m a second-year PhD student from FZ Jülich and member of HDS-LEE, currently visiting the ELPIS group as a HIDA Trainee to learn and work on Bayesian deep learning for uncertainty-aware single-cell microscopy analysis.","tags":null,"title":"Richard D. Paul","type":"authors"},{"authors":null,"categories":null,"content":"I’m Sara, a master’s student of Mathematics in Data Science at TUM, where I focused on courses in Machine Learning and Natural Language Processing. I am also working in a consumer alternative data firm as a data analyst.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"9f1ee531671002e8eaae73799e90e7a5","permalink":"https://fortuinlab.github.io/author/sara-visconti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sara-visconti/","section":"authors","summary":"I’m Sara, a master’s student of Mathematics in Data Science at TUM, where I focused on courses in Machine Learning and Natural Language Processing. I am also working in a consumer alternative data firm as a data analyst.","tags":null,"title":"Sara Visconti","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://fortuinlab.github.io/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":["James Odgers","Ruby Sedgwick","Chrysoula Kappatou","Ruth Misener","Sarah Filippi"],"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"9bd8561124eb8f812cf518bdcaf2727d","permalink":"https://fortuinlab.github.io/publication/odgers-2025-weightedsumgaussianprocesslatent/","publishdate":"2025-03-20T09:52:35.060674Z","relpermalink":"/publication/odgers-2025-weightedsumgaussianprocesslatent/","section":"publication","summary":"","tags":null,"title":"Weighted-Sum of Gaussian Process Latent Variable Models","type":"publication"},{"authors":["Kseniya Petrova","Maksym Tretiakov","Aleksandr Kotov","Anne H. Monsoro-Burq","Leonid Peshkin"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"aa7cedd6cb7a57aea0383699536b7cdc","permalink":"https://fortuinlab.github.io/publication/petrova-2024-atlas/","publishdate":"2025-03-20T09:52:35.117474Z","relpermalink":"/publication/petrova-2024-atlas/","section":"publication","summary":"","tags":null,"title":"A revised single-cell transcriptomic atlas of Xenopus embryo reveals new differentiation dynamics","type":"publication"},{"authors":["Lena Zellinger","Andreas Stephan","Benjamin Roth"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"3ec4752d552d0684b6fd493d6f0ea2dd","permalink":"https://fortuinlab.github.io/publication/zellinger-etal-2024-counterfactual/","publishdate":"2025-03-20T09:52:35.162022Z","relpermalink":"/publication/zellinger-etal-2024-counterfactual/","section":"publication","summary":"","tags":null,"title":"Counterfactual Reasoning with Knowledge Graph Embeddings","type":"publication"},{"authors":["Tristan Cinquin","Marvin Pförtner","Vincent Fortuin","Philipp Hennig","Robert Bamler"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"c575822fa5a7fee5f444a958a30e8818","permalink":"https://fortuinlab.github.io/publication/cinquin-2024-fsp/","publishdate":"2025-03-20T09:52:35.248913Z","relpermalink":"/publication/cinquin-2024-fsp/","section":"publication","summary":"","tags":null,"title":"FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning","type":"publication"},{"authors":["Emre Onal","Klemens Flöge","Emma Caldwell","Arsen Sheverdin","Vincent Fortuin"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"284b1d59deaafd3ae78a00318500f678","permalink":"https://fortuinlab.github.io/publication/onal-2024-gaussian/","publishdate":"2025-03-20T09:52:35.207857Z","relpermalink":"/publication/onal-2024-gaussian/","section":"publication","summary":"","tags":null,"title":"Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of Large Language Models","type":"publication"},{"authors":["Alexander Möllers","Alexander Immer","Vincent Fortuin","Elvin Isufi"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"03153287a256f94692729871852edd3d","permalink":"https://fortuinlab.github.io/publication/mollers-2024-hodge/","publishdate":"2025-03-20T09:52:35.229405Z","relpermalink":"/publication/mollers-2024-hodge/","section":"publication","summary":"","tags":null,"title":"Hodge-Aware Contrastive Learning","type":"publication"},{"authors":["Agustinus Kristiadi","Felix Strieth-Kalthoff","Sriram Ganapathi Subramanian","Vincent Fortuin","Pascal Poupart","Geoff Pleiss"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"525007ed6c5fc8b00b9ed5711d69ac2f","permalink":"https://fortuinlab.github.io/publication/kristiadi-2024-useful/","publishdate":"2025-03-20T09:52:35.201307Z","relpermalink":"/publication/kristiadi-2024-useful/","section":"publication","summary":"","tags":null,"title":"How Useful is Intermittent, Asynchronous Expert Feedback for Bayesian Optimization?","type":"publication"},{"authors":["Kouroche Bouchiat","Alexander Immer","Hugo Yèche","Gunnar Rätsch","Vincent Fortuin"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"f49f7fcae2f4178af88b8a01b2dcaaa7","permalink":"https://fortuinlab.github.io/publication/bouchiat-2024-improving/","publishdate":"2025-03-20T09:52:35.255383Z","relpermalink":"/publication/bouchiat-2024-improving/","section":"publication","summary":"","tags":null,"title":"Improving Neural Additive Models with Bayesian Principles","type":"publication"},{"authors":["Mrinank Sharma","Tom Rainforth","Yee Whye Teh","Vincent Fortuin"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"6d22523074b582d13d74a313f7fe75da","permalink":"https://fortuinlab.github.io/publication/sharma-2024-incorporating/","publishdate":"2025-03-20T09:52:35.261806Z","relpermalink":"/publication/sharma-2024-incorporating/","section":"publication","summary":"","tags":null,"title":"Incorporating Unlabelled Data into Bayesian Neural Networks","type":"publication"},{"authors":["Laura Manduchi","Kushagra Pandey","Robert Bamler","Ryan Cotterell","Sina Däubener","Sophie Fellenz","Asja Fischer","Thomas Gärtner","Matthias Kirchler","Marius Kloft","Yingzhen Li","Christoph Lippert","Gerard de Melo","Eric Nalisnick","Björn Ommer","Rajesh Ranganath","Maja Rudolph","Karen Ullrich","Guy Van den Broeck","Julia E Vogt","Yixin Wang","Florian Wenzel","Frank Wood","Stephan Mandt","Vincent Fortuin"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"5712403b72a05526813b6b24e442a13b","permalink":"https://fortuinlab.github.io/publication/manduchi-2024-challenges/","publishdate":"2025-03-20T09:52:35.214523Z","relpermalink":"/publication/manduchi-2024-challenges/","section":"publication","summary":"","tags":null,"title":"On the Challenges and Opportunities in Generative AI","type":"publication"},{"authors":["Richard D Paul","Alessio Quercia","Vincent Fortuin","Katharina Nöh","Hanno Scharr"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"442813d810c7a0c73a99b231b87b1c9f","permalink":"https://fortuinlab.github.io/publication/paul-2024-parameter/","publishdate":"2025-03-20T09:52:35.181212Z","relpermalink":"/publication/paul-2024-parameter/","section":"publication","summary":"","tags":null,"title":"Parameter-efficient Bayesian Neural Networks for Uncertainty-aware Depth Estimation","type":"publication"},{"authors":["Theodore Papamarkou","Maria Skoularidou","Konstantina Palla","Laurence Aitchison","Julyan Arbel","David Dunson","Maurizio Filippone","Vincent Fortuin","Philipp Hennig","Aliaksandr Hubin","Alexander Immer","Theofanis Karaletsos","Mohammad Emtiyaz Khan","Agustinus Kristiadi","Yingzhen Li","Stephan Mandt","Christopher Nemeth","Michael A Osborne","Tim GJ Rudner","David Rügamer","Yee Whye Teh","Max Welling","Andrew Gordon Wilson","Ruqi Zhang"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"39adec88e2369094adc8fc3da8dbcb4a","permalink":"https://fortuinlab.github.io/publication/papamarkou-2024-position/","publishdate":"2025-03-20T09:52:35.221893Z","relpermalink":"/publication/papamarkou-2024-position/","section":"publication","summary":"","tags":null,"title":"Position: Bayesian Deep Learning is Needed in the Age of Large-Scale AI","type":"publication"},{"authors":["Rayen Dhahri","Alexander Immer","Betrand Charpentier","Stephan Günnemann","Vincent Fortuin"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"c2c1d0c858d98f87f5fafc62f4798f74","permalink":"https://fortuinlab.github.io/publication/dhahri-2024-shaving/","publishdate":"2025-03-20T09:52:35.242498Z","relpermalink":"/publication/dhahri-2024-shaving/","section":"publication","summary":"","tags":null,"title":"Shaving Weights with Occam's Razor: Bayesian Sparsification for Neural Networks Using the Marginal Likelihood","type":"publication"},{"authors":["Klemens Flöge","Muhammad Abdul Moeed","Vincent Fortuin"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"cbbea8dede09d4fa9e3c315601dfe967","permalink":"https://fortuinlab.github.io/publication/floege-2024-stein/","publishdate":"2025-03-20T09:52:35.194745Z","relpermalink":"/publication/floege-2024-stein/","section":"publication","summary":"","tags":null,"title":"Stein Variational Newton Neural Network Ensembles","type":"publication"},{"authors":["Tommy Rochussen"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"604803f6800480297207792850bb3a3d","permalink":"https://fortuinlab.github.io/publication/rochussen-2024-structured/","publishdate":"2025-03-20T09:52:35.168276Z","relpermalink":"/publication/rochussen-2024-structured/","section":"publication","summary":"","tags":null,"title":"Structured Partial Stochasticity in Bayesian Neural Networks","type":"publication"},{"authors":["Fedor Sergeev","Paola Malsot","Gunnar Rätsch","Vincent Fortuin"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"78db1023bce616f251873cd4b8746f96","permalink":"https://fortuinlab.github.io/publication/sergeev-2024-towards/","publishdate":"2025-03-20T09:52:35.187733Z","relpermalink":"/publication/sergeev-2024-towards/","section":"publication","summary":"","tags":null,"title":"Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information","type":"publication"},{"authors":["Eliot Wong-Toi","Alex Boyd","Vincent Fortuin","Stephan Mandt"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"d1db3694352cd71de28f08d5c6e96dee","permalink":"https://fortuinlab.github.io/publication/wong-2024-understanding/","publishdate":"2025-03-20T09:52:35.235914Z","relpermalink":"/publication/wong-2024-understanding/","section":"publication","summary":"","tags":null,"title":"Understanding pathologies of deep heteroskedastic regression","type":"publication"},{"authors":["Julyan Arbel","Konstantinos Pitas","Mariia Vladimirova","Vincent Fortuin"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"392e8b514e5f9cce68200b3d9a49f6a1","permalink":"https://fortuinlab.github.io/publication/arbel-2023-primer/","publishdate":"2025-03-20T09:52:35.274841Z","relpermalink":"/publication/arbel-2023-primer/","section":"publication","summary":"","tags":null,"title":"A primer on Bayesian neural networks: review and debates","type":"publication"},{"authors":["Matthew Ashman","Tommy Rochussen","Adrian Weller"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"8b83f1e48e8f378981fb5c9d705fd127","permalink":"https://fortuinlab.github.io/publication/ashman-2023-amortised/","publishdate":"2025-03-20T09:52:35.174677Z","relpermalink":"/publication/ashman-2023-amortised/","section":"publication","summary":"","tags":null,"title":"Amortised Inference in Neural Networks for Small-Scale Probabilistic Meta-Learning","type":"publication"},{"authors":["Vincent Fortuin","Yingzhen Li","Kevin Murphy","Stephan Mandt","Laura Manduchi"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"5afdb2e9a6474a14243ce4c0ce6c298d","permalink":"https://fortuinlab.github.io/publication/fortuin-2023-challenges/","publishdate":"2025-03-20T09:52:35.281391Z","relpermalink":"/publication/fortuin-2023-challenges/","section":"publication","summary":"","tags":null,"title":"Challenges and Perspectives in Deep Generative Modeling (Dagstuhl Seminar 23072)","type":"publication"},{"authors":["Szilvia Ujváry","Gergely Flamich","Vincent Fortuin","José Miguel Hernández Lobato"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"d7f046761990cd594ede8d123230ca6c","permalink":"https://fortuinlab.github.io/publication/ujvary-2023-estimating/","publishdate":"2025-03-20T09:52:35.268209Z","relpermalink":"/publication/ujvary-2023-estimating/","section":"publication","summary":"","tags":null,"title":"Estimating optimal PAC-Bayes bounds with Hamiltonian Monte Carlo","type":"publication"},{"authors":["Anastasiia Sedova","Lena Zellinger","Benjamin Roth"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"f6e4b08af2239bc75811746534310a50","permalink":"https://fortuinlab.github.io/publication/sedova-2023-learning/","publishdate":"2025-03-20T09:52:35.15578Z","relpermalink":"/publication/sedova-2023-learning/","section":"publication","summary":"","tags":null,"title":"Learning with noisy labels by adaptive gradient-based outlier removal","type":"publication"},{"authors":["James Odgers","Chrysoula Kappatou","Ruth Misener","Salvador Garcı́a Muñoz","Sarah Filippi"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"7fff5edfdf0a24610ca3b61ccc5aad1c","permalink":"https://fortuinlab.github.io/publication/odgers-2023-probabilistic/","publishdate":"2025-03-20T09:52:35.070295Z","relpermalink":"/publication/odgers-2023-probabilistic/","section":"publication","summary":"","tags":null,"title":"Probabilistic predictions for partial least squares using bootstrap","type":"publication"},{"authors":["Agustinus Kristiadi","Alexander Immer","Runa Eschenhagen","Vincent Fortuin"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"3cc8eec484aa98f029b78ba390d84859","permalink":"https://fortuinlab.github.io/publication/kristiadi-2023-promises/","publishdate":"2025-03-20T09:52:35.300877Z","relpermalink":"/publication/kristiadi-2023-promises/","section":"publication","summary":"","tags":null,"title":"Promises and Pitfalls of the Linearized Laplace in Bayesian Optimization","type":"publication"},{"authors":["Jonas Rothfuss","Martin Josifoski","Vincent Fortuin","Andreas Krause"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"f1ec581d03a95e99bac89aef07d305bc","permalink":"https://fortuinlab.github.io/publication/rothfuss-2023-scalable/","publishdate":"2025-03-20T09:52:35.288014Z","relpermalink":"/publication/rothfuss-2023-scalable/","section":"publication","summary":"","tags":null,"title":"Scalable PAC-Bayesian Meta-Learning via the PAC-Optimal Hyper-Posterior: From Theory to Practice","type":"publication"},{"authors":["Alexander Möllers","Alexander Immer","Elvin Isufi","Vincent Fortuin"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"f2d7b49f24d540754c9f3493c6fef28d","permalink":"https://fortuinlab.github.io/publication/moellers-2023-uncertainty/","publishdate":"2025-03-20T09:52:35.294493Z","relpermalink":"/publication/moellers-2023-uncertainty/","section":"publication","summary":"","tags":null,"title":"Uncertainty in Graph Contrastive Learning with Bayesian Neural Networks","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://fortuinlab.github.io/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://fortuinlab.github.io/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"landing"},{"authors":["Zhenisbek Assylbekov","Sultan Nurmukhamedov","Arsen Sheverdin","Thomas Mach"],"categories":null,"content":"","date":1651363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651363200,"objectID":"05f1d8eb60c5a7e2c25553174ea6cee7","permalink":"https://fortuinlab.github.io/publication/assylbekov-2022-hyperbolic/","publishdate":"2025-03-20T09:52:35.090764Z","relpermalink":"/publication/assylbekov-2022-hyperbolic/","section":"publication","summary":"","tags":null,"title":"From Hyperbolic Geometry Back to Word Embeddings","type":"publication"},{"authors":["Vincent Fortuin","Adrià Garriga-Alonso","Sebastian W Ober","Florian Wenzel","Gunnar Rätsch","Richard E Turner","Mark van der Wilk","Laurence Aitchison"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"9f647c28771ee359e8aa0ae1052c84f2","permalink":"https://fortuinlab.github.io/publication/fortuin-2022-bayesian/","publishdate":"2025-03-20T09:52:35.326941Z","relpermalink":"/publication/fortuin-2022-bayesian/","section":"publication","summary":"","tags":null,"title":"Bayesian neural network priors revisited","type":"publication"},{"authors":["Seth Nabarro","Stoil Ganev","Adrià Garriga-Alonso","Vincent Fortuin","Mark van der Wilk","Laurence Aitchison"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"e60308b80ac73327c04cd6f6af699162","permalink":"https://fortuinlab.github.io/publication/nabarro-2022-data/","publishdate":"2025-03-20T09:52:35.313807Z","relpermalink":"/publication/nabarro-2022-data/","section":"publication","summary":"","tags":null,"title":"Data augmentation in Bayesian neural networks and the cold posterior effect","type":"publication"},{"authors":["Vincent Fortuin","Mark Collier","Florian Wenzel","James Urquhart Allingham","Jeremiah Zhe Liu","Dustin Tran","Balaji Lakshminarayanan","Jesse Berent","Rodolphe Jenatton","Effrosyni Kokiopoulou"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"3a94d58727d04d1a414c006f90fd402c","permalink":"https://fortuinlab.github.io/publication/fortuin-2022-deep/","publishdate":"2025-03-20T09:52:35.320273Z","relpermalink":"/publication/fortuin-2022-deep/","section":"publication","summary":"","tags":null,"title":"Deep classifiers with label noise modeling and distance awareness","type":"publication"},{"authors":["Oren Sultan","Rayen Dhahri","Yauheni Mardan","Tobias Eder","Georg Groh"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"4830a1f35e9330cf1968bb347de89d2f","permalink":"https://fortuinlab.github.io/publication/sultan-2022-judgements/","publishdate":"2025-03-20T09:52:35.124036Z","relpermalink":"/publication/sultan-2022-judgements/","section":"publication","summary":"","tags":null,"title":"From Judgement's Premises Towards Key Points","type":"publication"},{"authors":["Alexander Immer","Tycho van der Ouderaa","Gunnar Rätsch","Vincent Fortuin","Mark van der Wilk"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"e51fff80cfb91cdad4cf3d3f5a6f0225","permalink":"https://fortuinlab.github.io/publication/immer-2022-invariance/","publishdate":"2025-03-20T09:52:35.30734Z","relpermalink":"/publication/immer-2022-invariance/","section":"publication","summary":"","tags":null,"title":"Invariance learning in deep neural networks with differentiable Laplace approximations","type":"publication"},{"authors":["Marcello Massimo Negri","Vincent Fortuin","Jan Stuehmer"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"fed9c41c60d08d9b302cbb75d93b3e56","permalink":"https://fortuinlab.github.io/publication/negri-2022-meta/","publishdate":"2025-03-20T09:52:35.333749Z","relpermalink":"/publication/negri-2022-meta/","section":"publication","summary":"","tags":null,"title":"Meta-learning richer priors for VAEs","type":"publication"},{"authors":["Lauro Langosco di Langosco","Vincent Fortuin","Heiko Strathmann"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"2528357ca3684bcc8a30d3c505050ae0","permalink":"https://fortuinlab.github.io/publication/langosco-2022-neural/","publishdate":"2025-03-20T09:52:35.340186Z","relpermalink":"/publication/langosco-2022-neural/","section":"publication","summary":"","tags":null,"title":"Neural Variational Gradient Descent","type":"publication"},{"authors":["Simon Bing","Vincent Fortuin","Gunnar Rätsch"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"e7ad9e41f0989c9cddb301129e022920","permalink":"https://fortuinlab.github.io/publication/bing-2022-disentanglement/","publishdate":"2025-03-20T09:52:35.346492Z","relpermalink":"/publication/bing-2022-disentanglement/","section":"publication","summary":"","tags":null,"title":"On Disentanglement in Gaussian Process Variational Autoencoders","type":"publication"},{"authors":["Florian Schottmann","Vincent Fortuin","Edoardo Ponti","Ryan Cotterell"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"9afe435ed6d6181585a3fd0e35800150","permalink":"https://fortuinlab.github.io/publication/schottmann-2022-interpretable/","publishdate":"2025-03-20T09:52:35.352814Z","relpermalink":"/publication/schottmann-2022-interpretable/","section":"publication","summary":"","tags":null,"title":"On Interpretable Reranking-Based Dependency Parsing Systems","type":"publication"},{"authors":["Tristan Cinquin","Alexander Immer","Max Horn","Vincent Fortuin"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"73490bdc8d935c630f1ef930c20086bf","permalink":"https://fortuinlab.github.io/publication/cinquin-2022-pathologies/","publishdate":"2025-03-20T09:52:35.358915Z","relpermalink":"/publication/cinquin-2022-pathologies/","section":"publication","summary":"","tags":null,"title":"Pathologies in Priors and Inference for Bayesian Transformers","type":"publication"},{"authors":["Vincent Fortuin"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"aa2ff0869458b7d16576f734731d548d","permalink":"https://fortuinlab.github.io/publication/fortuin-2022-priors/","publishdate":"2025-03-20T09:52:35.365323Z","relpermalink":"/publication/fortuin-2022-priors/","section":"publication","summary":"","tags":null,"title":"Priors in Bayesian deep learning: A review","type":"publication"},{"authors":["Alexander Immer","Lucas Torroba Hennigen","Vincent Fortuin","Ryan Cotterell"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"c7c98f513bb52fec7988e9a481c3727b","permalink":"https://fortuinlab.github.io/publication/immer-2022-probing/","publishdate":"2025-03-20T09:52:35.371568Z","relpermalink":"/publication/immer-2022-probing/","section":"publication","summary":"","tags":null,"title":"Probing as quantifying inductive bias","type":"publication"},{"authors":["Noah Berner","Vincent Fortuin","Jonas Landman"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"aa7785ae32e07674ba5746c4533813ed","permalink":"https://fortuinlab.github.io/publication/berner-2022-quantum/","publishdate":"2025-03-20T09:52:35.378106Z","relpermalink":"/publication/berner-2022-quantum/","section":"publication","summary":"","tags":null,"title":"Quantum Bayesian Neural Networks","type":"publication"},{"authors":["James Urquhart Allingham","Florian Wenzel","Zelda E Mariet","Basil Mustafa","Joan Puigcerver","Neil Houlsby","Ghassen Jerfel","Vincent Fortuin","Balaji Lakshminarayanan","Jasper Snoek","Dustin Tran","Carlos Riquelme Ruiz","Rodolphe Jenatton"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"7623f609d01c4e9b566fbd970fcfaf39","permalink":"https://fortuinlab.github.io/publication/allingham-2022-sparse/","publishdate":"2025-03-20T09:52:35.384529Z","relpermalink":"/publication/allingham-2022-sparse/","section":"publication","summary":"","tags":null,"title":"Sparse MoEs meet Efficient Ensembles","type":"publication"},{"authors":["Nikolaos Mourdoukoutas","Marco Federici","Georges Pantalos","Mark van der Wilk","Vincent Fortuin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"c58dd1b5242627da7da4b8f98458aaf0","permalink":"https://fortuinlab.github.io/publication/mourdoukoutas-2021-bayesian/","publishdate":"2025-03-20T09:52:35.424408Z","relpermalink":"/publication/mourdoukoutas-2021-bayesian/","section":"publication","summary":"","tags":null,"title":"A Bayesian Approach to Invariant Deep Neural Networks","type":"publication"},{"authors":["Francesco D'Angelo","Vincent Fortuin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"fc4191e4067d03f84b9c57139ab8f38b","permalink":"https://fortuinlab.github.io/publication/dangelo-2021-annealed/","publishdate":"2025-03-20T09:52:35.404506Z","relpermalink":"/publication/dangelo-2021-annealed/","section":"publication","summary":"","tags":null,"title":"Annealed Stein Variational Gradient Descent","type":"publication"},{"authors":["Vincent Fortuin","Adrià Garriga-Alonso","Mark van der Wilk","Laurence Aitchison"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"4459bbb86fdc8ae5b01e7e6c6489b956","permalink":"https://fortuinlab.github.io/publication/fortuin-2021-bnnpriors/","publishdate":"2025-03-20T09:52:35.411207Z","relpermalink":"/publication/fortuin-2021-bnnpriors/","section":"publication","summary":"","tags":null,"title":"BNNpriors: A library for Bayesian neural network inference with different prior distributions","type":"publication"},{"authors":["Igor B Petrov","Maksim V Muratov","Fedor I Sergeev"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"75b315f5c7f78fc8d015c4a8b029d7a8","permalink":"https://fortuinlab.github.io/publication/petrov-2021-elastic/","publishdate":"2025-03-20T09:52:35.142641Z","relpermalink":"/publication/petrov-2021-elastic/","section":"publication","summary":"","tags":null,"title":"Elastic wave propagation modeling during exploratory drilling on artificial ice island","type":"publication"},{"authors":["Adrià Garriga-Alonso","Vincent Fortuin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"89c7089c5f90462d9798528c183b7686","permalink":"https://fortuinlab.github.io/publication/garriga-2021-exact/","publishdate":"2025-03-20T09:52:35.41803Z","relpermalink":"/publication/garriga-2021-exact/","section":"publication","summary":"","tags":null,"title":"Exact Langevin Dynamics with Stochastic Gradients","type":"publication"},{"authors":["Metod Jazbec","Michael Arthur Leopold Pearce","Vincent Fortuin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"c82c03846b2bddeb6d21135352fe55de","permalink":"https://fortuinlab.github.io/publication/jazbec-2021-factorized/","publishdate":"2025-03-20T09:52:35.490378Z","relpermalink":"/publication/jazbec-2021-factorized/","section":"publication","summary":"","tags":null,"title":"Factorized Gaussian Process Variational Autoencoders","type":"publication"},{"authors":["Fedor Sergeev","Nikita Jain","Ivan Knunyants","George Kostenkov","Ekaterina Trofimova"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"281b0f50103bd3d41a7bc398f41fbf94","permalink":"https://fortuinlab.github.io/publication/sergeev-2021-fast/","publishdate":"2025-03-20T09:52:35.130423Z","relpermalink":"/publication/sergeev-2021-fast/","section":"publication","summary":"","tags":null,"title":"Fast simulation of the LHCb electromagnetic calorimeter response using VAEs and GANs","type":"publication"},{"authors":["Margherita Rosnati","Vincent Fortuin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"fc55ebeb609b27aba07ce2e476f1e3a0","permalink":"https://fortuinlab.github.io/publication/rosnati-2021-mgp/","publishdate":"2025-03-20T09:52:35.431102Z","relpermalink":"/publication/rosnati-2021-mgp/","section":"publication","summary":"","tags":null,"title":"MGP-AttTCN: An interpretable machine learning model for the prediction of sepsis","type":"publication"},{"authors":["Andreas Kopf","Vincent Fortuin","Vignesh Ram Somnath","Manfred Claassen"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"d70c9e903db4994a9e644d935eb41e1b","permalink":"https://fortuinlab.github.io/publication/kopf-2021-mixture/","publishdate":"2025-03-20T09:52:35.437455Z","relpermalink":"/publication/kopf-2021-mixture/","section":"publication","summary":"","tags":null,"title":"Mixture-of-Experts Variational Autoencoder for clustering and generating from similarity-based representations on single cell data","type":"publication"},{"authors":["Francesco D'Angelo","Vincent Fortuin","Florian Wenzel"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"c3eea0ce6ff22b38a08dedff84b8c455","permalink":"https://fortuinlab.github.io/publication/dangelo-2021-stein/","publishdate":"2025-03-20T09:52:35.444083Z","relpermalink":"/publication/dangelo-2021-stein/","section":"publication","summary":"","tags":null,"title":"On Stein variational neural network ensembles","type":"publication"},{"authors":["Vincent Fortuin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"351a88cda984b37369a76ab59b7fd012","permalink":"https://fortuinlab.github.io/publication/fortuin-2021-choice/","publishdate":"2025-03-20T09:52:35.391443Z","relpermalink":"/publication/fortuin-2021-choice/","section":"publication","summary":"","tags":null,"title":"On the Choice of Priors in Bayesian Deep Learning","type":"publication"},{"authors":["Jonas Rothfuss","Vincent Fortuin","Martin Josifoski","Andreas Krause"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"73392b9c1ca7cea438242838ecb96ee8","permalink":"https://fortuinlab.github.io/publication/rothfuss-2021-pacoh/","publishdate":"2025-03-20T09:52:35.450584Z","relpermalink":"/publication/rothfuss-2021-pacoh/","section":"publication","summary":"","tags":null,"title":"PACOH: Bayes-optimal meta-learning with PAC-guarantees","type":"publication"},{"authors":["Alexandre Bense","Amir Joudaki","Tim GJ Rudner","Vincent Fortuin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"390ad24b56e1d5f905e250c15b1f4828","permalink":"https://fortuinlab.github.io/publication/bense-2021-pca/","publishdate":"2025-03-20T09:52:35.46354Z","relpermalink":"/publication/bense-2021-pca/","section":"publication","summary":"","tags":null,"title":"PCA Subspaces Are Not Always Optimal for Bayesian Learning","type":"publication"},{"authors":["Arsen Sheverdin","Noud Corten","Alko Knijff","Georg Lange"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"a878fb0b40c11ee5dc8bcc744e39fc32","permalink":"https://fortuinlab.github.io/publication/sheverdin-2021-reproducibility/","publishdate":"2025-03-20T09:52:35.10426Z","relpermalink":"/publication/sheverdin-2021-reproducibility/","section":"publication","summary":"","tags":null,"title":"Reproducibility report for ''Interpretable Complex-Valued Neural Networks for Privacy Protection''","type":"publication"},{"authors":["Francesco D'Angelo","Vincent Fortuin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"65bd1d86dcab22dd393489eab0216766","permalink":"https://fortuinlab.github.io/publication/dangelo-2021-repulsive/","publishdate":"2025-03-20T09:52:35.457071Z","relpermalink":"/publication/dangelo-2021-repulsive/","section":"publication","summary":"","tags":null,"title":"Repulsive deep ensembles are Bayesian","type":"publication"},{"authors":["Metod Jazbec","Matt Ashman","Vincent Fortuin","Michael Pearce","Stephan Mandt","Gunnar Rätsch"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"4ead010c8eb32a08f227db8daf422e56","permalink":"https://fortuinlab.github.io/publication/jazbec-2021-scalable/","publishdate":"2025-03-20T09:52:35.470273Z","relpermalink":"/publication/jazbec-2021-scalable/","section":"publication","summary":"","tags":null,"title":"Scalable Gaussian process variational autoencoders","type":"publication"},{"authors":["Alexander Immer","Matthias Bauer","Vincent Fortuin","Gunnar Rätsch","Mohammad Emtiyaz Khan"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"3a5c4ee915e9c9244224f1bef05fd270","permalink":"https://fortuinlab.github.io/publication/immer-2021-scalable/","publishdate":"2025-03-20T09:52:35.477033Z","relpermalink":"/publication/immer-2021-scalable/","section":"publication","summary":"","tags":null,"title":"Scalable marginal likelihood estimation for model selection in deep learning","type":"publication"},{"authors":["Vincent Fortuin","Gideon Dresdner","Heiko Strathmann","Gunnar Rätsch"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"4caed40ea978f3399b9ee15f72b53003","permalink":"https://fortuinlab.github.io/publication/fortuin-2021-sparse/","publishdate":"2025-03-20T09:52:35.483798Z","relpermalink":"/publication/fortuin-2021-sparse/","section":"publication","summary":"","tags":null,"title":"Sparse Gaussian processes on discrete domains","type":"publication"},{"authors":["Laura Manduchi","Matthias Hüser","Martin Faltys","Julia Vogt","Gunnar Rätsch","Vincent Fortuin"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"ac8b839169b2ec49d3d8e9200fdb891d","permalink":"https://fortuinlab.github.io/publication/manduchi-2021-tdpsom/","publishdate":"2025-03-20T09:52:35.397811Z","relpermalink":"/publication/manduchi-2021-tdpsom/","section":"publication","summary":"","tags":null,"title":"T-DPSOM: An interpretable clustering method for unsupervised learning of patient health states","type":"publication"},{"authors":["Arsen Sheverdin","Francesco Monticone","Constantinos Valagiannopoulos"],"categories":null,"content":"","date":159624e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":159624e4,"objectID":"2e259c2edde83cfa7f9c7f5ea7a16a99","permalink":"https://fortuinlab.github.io/publication/sheverdin-2020-photonic/","publishdate":"2025-03-20T09:52:35.0975Z","relpermalink":"/publication/sheverdin-2020-photonic/","section":"publication","summary":"","tags":null,"title":"Photonic Inverse Design with Neural Networks: The Case of Invisibility in the Visible","type":"publication"},{"authors":["Kamil Ciosek","Vincent Fortuin","Ryota Tomioka","Katja Hofmann","Richard Turner"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"6437113dfa7e62102706742a1f0e2259","permalink":"https://fortuinlab.github.io/publication/ciosek-2020-conservative/","publishdate":"2025-03-20T09:52:35.497093Z","relpermalink":"/publication/ciosek-2020-conservative/","section":"publication","summary":"","tags":null,"title":"Conservative uncertainty estimation by fitting prior networks","type":"publication"},{"authors":["Fedor Sergeev","Elena Bratkovskaya","Ivan Kisel","Iouri Vassiliev"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"275d569e82031ccaae110ad45e51fb2c","permalink":"https://fortuinlab.github.io/publication/sergeev-2020-deep/","publishdate":"2025-03-20T09:52:35.136604Z","relpermalink":"/publication/sergeev-2020-deep/","section":"publication","summary":"","tags":null,"title":"Deep learning for quark--gluon plasma detection in the CBM experiment","type":"publication"},{"authors":["D Beznosko","K Yelshibekov","R U Beisembaev","E A Beisembaeva","T Beremkulov","A Iakovlev","S Jakupov","A Sheverdin","Z Tagay","T Uakhitov","M I Vildanova","V V Zhukov"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"7ac2a8805d3710cfa0454b0dc2f071d5","permalink":"https://fortuinlab.github.io/publication/beznosko-2020-extensive/","publishdate":"2025-03-20T09:52:35.083782Z","relpermalink":"/publication/beznosko-2020-extensive/","section":"publication","summary":"","tags":null,"title":"Extensive air showers event reconstruction using spatial and temporary particle distribution at Horizon-T experiment","type":"publication"},{"authors":["Vincent Fortuin","Dmitry Baranchuk","Gunnar Rätsch","Stephan Mandt"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"0122639d43ea3edd29a290eb77399406","permalink":"https://fortuinlab.github.io/publication/fortuin-2020-gp/","publishdate":"2025-03-20T09:52:35.503741Z","relpermalink":"/publication/fortuin-2020-gp/","section":"publication","summary":"","tags":null,"title":"GP-VAE: Deep probabilistic time series imputation","type":"publication"},{"authors":["Matthew Ashman","Jonathan So","Will Tebbutt","Vincent Fortuin","Michael Pearce","Richard E Turner"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"dd304fca001977c180f9cb5f384b81af","permalink":"https://fortuinlab.github.io/publication/ashman-2020-sparse/","publishdate":"2025-03-20T09:52:35.510602Z","relpermalink":"/publication/ashman-2020-sparse/","section":"publication","summary":"","tags":null,"title":"Sparse Gaussian process variational autoencoders","type":"publication"},{"authors":["Igor Borisovich Petrov","Maksim Viktorovich Muratov","Fedor Igorevich Sergeev"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"0e60b3b44cc6578291e3e24846216bdf","permalink":"https://fortuinlab.github.io/publication/petrov-2020-stability/","publishdate":"2025-03-20T09:52:35.148817Z","relpermalink":"/publication/petrov-2020-stability/","section":"publication","summary":"","tags":null,"title":"Stability analysis of artificial ice islands by methods of mathematical modeling","type":"publication"},{"authors":["Arsen Sheverdin","Constantinos Valagiannopoulos"],"categories":null,"content":"","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"5b19fecbe194a776d4a82532d0eb6592","permalink":"https://fortuinlab.github.io/publication/sheverdin-2019-coreshell/","publishdate":"2025-03-20T09:52:35.077057Z","relpermalink":"/publication/sheverdin-2019-coreshell/","section":"publication","summary":"","tags":null,"title":"Core-shell nanospheres under visible light: Optimal absorption, scattering, and cloaking","type":"publication"},{"authors":["Laura Manduchi","Matthias Hüser","Julia Vogt","Gunnar Rätsch","Vincent Fortuin"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"f263e25e6ad4a13193117050ca3a1fd9","permalink":"https://fortuinlab.github.io/publication/manduchi-2019-dpsom/","publishdate":"2025-03-20T09:52:35.517254Z","relpermalink":"/publication/manduchi-2019-dpsom/","section":"publication","summary":"","tags":null,"title":"DPSOM: Deep probabilistic clustering with self-organizing maps","type":"publication"},{"authors":["Constantinos Valagiannopoulos","Arsen Sheverdin","Adilkhan Sarsen","Aivar Abrashuly"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"cbbb55a5d6e519e31ea4feb42ba9d4c5","permalink":"https://fortuinlab.github.io/publication/valagiannopoulos-2019-maximizing/","publishdate":"2025-03-20T09:52:35.110997Z","relpermalink":"/publication/valagiannopoulos-2019-maximizing/","section":"publication","summary":"","tags":null,"title":"Maximizing Photonic Response with Simple Resonating Structures in Various Geometries","type":"publication"},{"authors":["Vincent Fortuin","Heiko Strathmann","Gunnar Rätsch"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"b0ad5ef5ba31c5ec3f834505d47ee0b9","permalink":"https://fortuinlab.github.io/publication/fortuin-2019-meta/","publishdate":"2025-03-20T09:52:35.537116Z","relpermalink":"/publication/fortuin-2019-meta/","section":"publication","summary":"","tags":null,"title":"Meta-learning mean functions for Gaussian processes","type":"publication"},{"authors":["Andreas Georgiou","Vincent Fortuin","Harun Mustafa","Gunnar Rätsch"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"8f0cc4e410406668d5a709c1f30e7b33","permalink":"https://fortuinlab.github.io/publication/georgiou-2019-meta/","publishdate":"2025-03-20T09:52:35.52391Z","relpermalink":"/publication/georgiou-2019-meta/","section":"publication","summary":"","tags":null,"title":"META$^2$: Memory-efficient taxonomic classification and abundance estimation for metagenomics with deep learning","type":"publication"},{"authors":["Vincent Fortuin","Matthias Hüser","Francesco Locatello","Heiko Strathmann","Gunnar Rätsch"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"d423f85de6335a4ffdbdc6992e83ca92","permalink":"https://fortuinlab.github.io/publication/fortuin-2019-som/","publishdate":"2025-03-20T09:52:35.530437Z","relpermalink":"/publication/fortuin-2019-som/","section":"publication","summary":"","tags":null,"title":"SOM-VAE: Interpretable discrete representation learning on time series","type":"publication"},{"authors":["Vincent Fortuin","Romann Weber","Sasha Schriber","Diana Wotruba","Markus Gross"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"2aee5ab3ead5927a79726db054e6e608","permalink":"https://fortuinlab.github.io/publication/fortuin-2018-inspireme/","publishdate":"2025-03-20T09:52:35.55663Z","relpermalink":"/publication/fortuin-2018-inspireme/","section":"publication","summary":"","tags":null,"title":"InspireMe: learning sequence models for stories","type":"publication"},{"authors":["Tim GJ Rudner","Vincent Fortuin","Yee Whye Teh","Yarin Gal"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"ec01cdc2d65eaeb95470295ecb8308dc","permalink":"https://fortuinlab.github.io/publication/rudner-2018-connection/","publishdate":"2025-03-20T09:52:35.550312Z","relpermalink":"/publication/rudner-2018-connection/","section":"publication","summary":"","tags":null,"title":"On the connection between neural processes and Gaussian processes with deep kernels","type":"publication"},{"authors":["Stefan Ganscha","Vincent Fortuin","Max Horn","Eirini Arvaniti","Manfred Claassen"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"2c5bc7172e6360306dc7b56226354d07","permalink":"https://fortuinlab.github.io/publication/ganscha-2018-supervised/","publishdate":"2025-03-20T09:52:35.543608Z","relpermalink":"/publication/ganscha-2018-supervised/","section":"publication","summary":"","tags":null,"title":"Supervised learning on synthetic data for reverse engineering gene regulatory networks from experimental time-series","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://fortuinlab.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"}]